import os
import traceback
import torch
from PIL import Image, ImageFont
import cv2
import numpy as np
import joblib
import facer
from fb import get_db
from sklearn.cluster import KMeans
from flask import Flask, request, jsonify, render_template, send_from_directory, session, send_file
from werkzeug.utils import secure_filename
import base64
from io import BytesIO
import json
import ssl
import time
import albumentations as A
from scipy import ndimage
from skimage import exposure, color
from werkzeug.security import generate_password_hash, check_password_hash

# PDF ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬
from fpdf import FPDF

# ê°€ìƒ ë©”ì´í¬ì—… ê¸°ëŠ¥ì— í•„ìš”í•œ import
from torchvision import transforms
from model import BiSeNet  # kaka í”„ë¡œì íŠ¸ì˜ model.py
from makeup import hair   # kaka í”„ë¡œì íŠ¸ì˜ makeup.py

# ==============================================================================
# SSL ì¸ì¦ì„œ ì˜¤ë¥˜ í•´ê²° (facer ëª¨ë¸ ë‹¤ìš´ë¡œë“œìš©)
# ==============================================================================
ssl._create_default_https_context = ssl._create_unverified_context

# Flask ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ì´ˆê¸°í™”
app = Flask(__name__, template_folder='templates', static_folder='static')
app.secret_key = os.urandom(24)

# ì›¹ì•± ê¸°ë³¸ ì„¤ì •
UPLOAD_FOLDER = 'uploads'
if not os.path.exists(UPLOAD_FOLDER):
    os.makedirs(UPLOAD_FOLDER)

app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
app.config['ALLOWED_EXTENSIONS'] = {'png', 'jpg', 'jpeg', 'webp'}
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024

# AI ëª¨ë¸ ê´€ë ¨ ì „ì—­ ë³€ìˆ˜
MODEL_DIR = '.'
N_REPRESENTATIVE_COLORS = 7
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# í¼ìŠ¤ë„ ì»¬ëŸ¬ íƒ€ì…ë³„ ì •ë³´ ë°ì´í„°
CLUSTER_DESCRIPTIONS = {
    0: {
        "name": "Golden",
        "visual_name": "ê³¨ë“  íƒ€ì…",
        "description": "í–‡ì‚´ì²˜ëŸ¼ ë”°ëœ»í•˜ê³  ìƒê¸° ë„˜ì¹˜ëŠ” ê³¨ë“œ í†¤ì…ë‹ˆë‹¤.",
        "palette": ["#FFE999", "#f7e6b5", "#E8A317", "#FFC800", "#E07223"]
    },
    1: {
        "name": "Warm Beige",
        "visual_name": "ì›œ ë² ì´ì§€ íƒ€ì…",
        "description": "ë”°ëœ»í•˜ë©´ì„œë„ ì€ì€í•œ ì˜¬ë¦¬ë¸Œ ê¸°ìš´ì„ ë¨¸ê¸ˆì€ ìƒ‰ê°ì…ë‹ˆë‹¤.",
        "palette": ["#FFF8E7", "#EEDC82", "#D2B48C", "#C68642", "#7A4A23"]
    },
    2: {
        "name": "Cool Rose",
        "visual_name": "ì¿¨ ë¡œì¦ˆ íƒ€ì…",
        "description": "ë§‘ê³  ì‹œì›í•œ ì¥ë¯¸ë¹›ì˜ ì¿¨ í•‘í¬ ë ˆë“œ ê³„ì—´ì…ë‹ˆë‹¤.",
        "palette": ["#FFC0CB", "#F08080", "#DB7093", "#FF69B4", "#C71585"]
    },
    3: {
        "name": "Muted Clay",
        "visual_name": "ë®¤íŠ¸ í´ë ˆì´ íƒ€ì…",
        "description": "ì°¨ë¶„í•˜ê³  ë¶€ë“œëŸ½ê²Œ í†¤ ë‹¤ìš´ëœ ë‰´íŠ¸ëŸ´ ë¬´ë“œì…ë‹ˆë‹¤.",
        "palette": ["#FBECE9", "#ECD4C1", "#D4B4A9", "#AB8F7E", "#CBB3A5"]
    },
    4: {
        "name": "Warm Apricot",
        "visual_name": "ì›œ ì• í”„ë¦¬ì½§ íƒ€ì…",
        "description": "í™”ì‚¬í•˜ë©´ì„œë„ í¬ê·¼í•œ ì˜¤ë Œì§€ë¹› ê³„ì—´ì…ë‹ˆë‹¤.",
        "palette": ["#FBCEB1", "#FFB84D", "#F4A460", "#E9967A", "#FF7F50"]
    },
    5: {
        "name": "Peachy Pink",
        "visual_name": "í”¼ì¹˜ í•‘í¬ íƒ€ì…",
        "description": "ì‚¬ë‘ìŠ¤ëŸ½ê³  ê²½ì¾Œí•œ í”¼ì¹˜ í•‘í¬ ê³„ì—´ì…ë‹ˆë‹¤.",
        "palette": ["#FFD7D1", "#FFCBA4", "#FF9999", "#FF6F61", "#E34260"]
    },
    6: {
        "name": "Honey Buff",
        "visual_name": "í—ˆë‹ˆ ë²„í”„ íƒ€ì…",
        "description": "ê¿€ì²˜ëŸ¼ ë”°ëœ»í•˜ê³  ë‹¬ì½¤í•œ ê³¨ë“  ë² ì´ì§€ ê³„ì—´ì…ë‹ˆë‹¤.",
        "palette": ["#FFD65C", "#E3C296", "#DDB67D", "#C8A165", "#DAA520"]
    },
    7: {
        "name": "Beige Rose",
        "visual_name": "ë² ì´ì§€ ë¡œì¦ˆ íƒ€ì…",
        "description": "ì€ì€í•˜ë©´ì„œë„ ë¡œë§¨í‹±í•œ ë² ì´ì§€ ë¡œì¦ˆ í†¤ì…ë‹ˆë‹¤.",
        "palette": ["#E8C2B3", "#EA9884", "#FF9099", "#D26676", "#7D3039"]
    }
}

# ê°€ìƒ ë©”ì´í¬ì—…ì— ì‚¬ìš©í•  ì»¬ëŸ¬ íŒ”ë ˆíŠ¸
MAKEOVER_PALETTES = {
    # 0: Golden
    0: [
        ["#A3894C", "#4C99A3", "#A34C7D", "#95A34C"],  # Style 1 (Natural)
        ["#A34C4C", "#7F9C92", "#C45A5A", "#A7B6B4"],  # Style 2 (Smokey)
        ["#8A3500", "#33A399", "#D1256A", "#512525"]   # Style 3 (Vibrant)
    ],
    # 1: Warm Beige
    1: [
        ["#F9D7B8", "#74A5BF", "#E59595", "#EEDC82"],  # Style 1 (Warm & Bright)
        ["#7A2E2E", "#4A7A99", "#D46B6B", "#B87B4F"],  # Style 2 (Deep & Elegant)
        ["#9B2047", "#62A062", "#9B2047", "#A0C9E0"]   # Style 3 (Soft & Earthy)
    ],
    # 2: Cool Rose
    2: [
        ["#C19A8B", "#5C7A86", "#A32E31", "#3A565A"],  # Style 1 (Ashy)
        ["#D1B7AA", "#9DB8B5", "#E5A4A4", "#D0BBDE"],  # Style 2 (Soft)
        ["#332436", "#8A3500", "#D1259A", "#58FFF4"]   # Style 3 (Fantasy)
    ],
    # 3: Muted Clay
    3: [
        ["#9E6B58", "#4A7E94", "#9E2A2B", "#EEFFA4"],  # Style 1 (Earthy)
        ["#CBB3A5", "#A9C6C2", "#E9A6A6", "#D7C4E0"],  # Style 2 (Soft)
        ["#5C4033", "#78866B", "#B87333", "#05A6B1"]   # Style 3 (Woodsy)
    ],
    # 4: Warm Apricot
    4: [
        ["#7B3F00", "#C49E3F", "#8B4D40", "#C2B280"],  # Style 1 (Natural)
        ["#2A252F", "#5C7A86", "#A32E31", "#3A565A"],  # Style 2 (Smokey)
        ["#E46253", "#50B2C0", "#FF6A8A", "#FF916F"]   # Style 3 (Tropical)
    ],
    # 5: Peachy Pink
    5: [
        ["#D8A47F", "#9FD9D9", "#F08A8A", "#F7E6C4"],  # Style 1 (Natural)
        ["#3B2F2F", "#6B8E23", "#C94C4C", "#A8B5BA"],  # Style 2 (Earthy)
        ["#E55986", "#5EC4D4", "#FF6B6B", "#FFD166"]   # Style 3 (Vivid)
    ],
    # 6: Honey Buff
    6: [
        ["#825F4E", "#567591", "#B56B81", "#FFECA1"],  # Style 1 (Natural)
        ["#994E63", "#0C4D1E", "#D16A5A", "#B0D9D8"],  # Style 2 (Smokey)
        ["#944D64", "#3BA6FD", "#CD5C8F", "#B0D9D8"]   # Style 3 (Bold)
    ],
    # 7: Beige Rose
    7: [
        ["#DDC2B4", "#BCA69A", "#D99A9A", "#B0D9D8"],  # Style 1 (Natural)
        ["#B17B78", "#C9D5D5", "#D97474", "#EBCFCF"],  # Style 2 (Soft Rose)
        ["#6A5ACD", "#20B2AA", "#F08080", "#3A565A"]   # Style 3 (Royal)
    ]
}


# AI ëª¨ë¸ ê´€ë ¨ ì „ì—­ ë³€ìˆ˜ ì´ˆê¸°í™”
kmeans_model = None
scaler = None
face_detector = None
face_parser = None
face_parsing_net = None # ê°€ìƒ ë©”ì´í¬ì—…ìš© ëª¨ë¸
models_loaded = False

# ì´ë¯¸ì§€ í…ì„œ ë³€í™˜ (ê°€ìƒ ë©”ì´í¬ì—…ìš©)
to_tensor = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),
])

def hex_to_bgr(hex_color):
    hex_color = hex_color.lstrip("#")
    r = int(hex_color[0:2],16)
    g = int(hex_color[2:4],16)
    b = int(hex_color[4:6],16)
    return [b,g,r]

# ==============================================================================
# PDF ê´€ë ¨ í—¬í¼ í•¨ìˆ˜
# ==============================================================================
from pdf import generate_report_pdf



# ==============================================================================
# ê³ ê¸‰ ì¡°ëª… ë³´ì • í•¨ìˆ˜ë“¤ (ê¸°ì¡´ê³¼ ë™ì¼)
# ==============================================================================
def analyze_lighting_conditions(image_np):
    """ì´ë¯¸ì§€ì˜ ì¡°ëª… ìƒíƒœë¥¼ ë¶„ì„í•˜ì—¬ ë³´ì • ì „ëµì„ ê²°ì •"""
    lab = cv2.cvtColor(image_np, cv2.COLOR_RGB2LAB)
    l_channel = lab[:, :, 0]
    mean_brightness = np.mean(l_channel)
    std_brightness = np.std(l_channel)
    dark_pixels = np.sum(l_channel < 85) / l_channel.size
    bright_pixels = np.sum(l_channel > 170) / l_channel.size
    return {
        'mean_brightness': mean_brightness, 'std_brightness': std_brightness,
        'dark_ratio': dark_pixels, 'bright_ratio': bright_pixels,
        'is_underexposed': mean_brightness < 120 and dark_pixels > 0.3,
        'is_overexposed': mean_brightness > 180 and bright_pixels > 0.2,
        'has_low_contrast': std_brightness < 25, 'has_uneven_lighting': std_brightness > 50
    }

def white_balance_correction(image_np, method='gray_world'):
    """í™”ì´íŠ¸ ë°¸ëŸ°ìŠ¤ ë³´ì •"""
    image = image_np.astype(np.float32) / 255.0
    if method == 'gray_world':
        mean_rgb = np.mean(image.reshape(-1, 3), axis=0)
        scale_factors = 0.5 / (mean_rgb + 1e-8)
        corrected = image * scale_factors
    elif method == 'white_patch':
        max_rgb = np.max(image.reshape(-1, 3), axis=0)
        scale_factors = 1.0 / (max_rgb + 1e-8)
        corrected = image * scale_factors
    else: # illuminant_estimation
        h, w = image.shape[:2]
        block_means = [np.mean(image[i:i+h//3, j:j+w//3].reshape(-1, 3), axis=0) for i in range(0, h, h//3) for j in range(0, w, w//3) if image[i:i+h//3, j:j+w//3].size > 0]
        if block_means:
            illuminant = np.array(block_means)[np.argmax(np.sum(block_means, axis=1))]
            scale_factors = 0.9 / (illuminant + 1e-8)
            corrected = image * scale_factors
        else:
            corrected = image
    return (np.clip(corrected, 0, 1) * 255).astype(np.uint8)

def adaptive_histogram_equalization(image_np, clip_limit=3.0, tile_grid_size=(8, 8)):
    """ì ì‘ì  íˆìŠ¤í† ê·¸ë¨ í‰í™œí™” (CLAHE)"""
    lab = cv2.cvtColor(image_np, cv2.COLOR_RGB2LAB)
    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)
    lab[:, :, 0] = clahe.apply(lab[:, :, 0])
    return cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)

def gamma_correction(image_np, gamma=1.0):
    """ê°ë§ˆ ë³´ì •"""
    inv_gamma = 1.0 / gamma
    table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype("uint8")
    return cv2.LUT(image_np, table)

def shadow_highlight_correction(image_np, shadow_amount=0.0, highlight_amount=0.0, shadow_width=50, highlight_width=50):
    """ê·¸ë¦¼ì/í•˜ì´ë¼ì´íŠ¸ ë³´ì •"""
    lab = cv2.cvtColor(image_np, cv2.COLOR_RGB2LAB).astype(np.float32)
    l_channel = lab[:, :, 0] / 255.0
    shadow_mask = np.exp(-((l_channel - 0.0) ** 2) / (2 * (shadow_width / 255.0) ** 2))
    highlight_mask = np.exp(-((l_channel - 1.0) ** 2) / (2 * (highlight_width / 255.0) ** 2))
    if shadow_amount != 0.0:
        l_channel += shadow_amount * shadow_mask * (1.0 - l_channel)
    if highlight_amount != 0.0:
        l_channel += highlight_amount * highlight_mask * (l_channel - 1.0)
    lab[:, :, 0] = np.clip(l_channel, 0, 1) * 255.0
    return cv2.cvtColor(lab.astype(np.uint8), cv2.COLOR_LAB2RGB)

def unsharp_masking(image_np, strength=0.5, radius=1.0, threshold=0.0):
    """ì–¸ìƒ¤í”„ ë§ˆìŠ¤í‚¹ì„ í†µí•œ ì„ ëª…ë„ í–¥ìƒ"""
    blurred = cv2.GaussianBlur(image_np, (0, 0), radius)
    mask = image_np.astype(np.float32) - blurred.astype(np.float32)
    if threshold > 0:
        mask = np.where(np.abs(mask) < threshold, 0, mask)
    sharpened = np.clip(image_np.astype(np.float32) + strength * mask, 0, 255).astype(np.uint8)
    return sharpened

def comprehensive_lighting_correction(image_np, lighting_info=None):
    """ì¢…í•©ì ì¸ ì¡°ëª… ë³´ì • íŒŒì´í”„ë¼ì¸"""
    if lighting_info is None:
        lighting_info = analyze_lighting_conditions(image_np)
    
    corrected = image_np.copy()
    correction_log = []
    
    wb_method = 'gray_world'
    if lighting_info['bright_ratio'] > 0.15: wb_method = 'white_patch'
    elif lighting_info['has_uneven_lighting']: wb_method = 'illuminant_estimation'
    corrected = white_balance_correction(corrected, method=wb_method)
    correction_log.append(f"White balance: {wb_method}")
    
    if lighting_info['is_underexposed']:
        corrected = shadow_highlight_correction(corrected, shadow_amount=0.3, highlight_amount=-0.1)
        corrected = gamma_correction(corrected, 0.7)
        correction_log.append("Underexposure correction: shadow lift + gamma 0.7")
    elif lighting_info['is_overexposed']:
        corrected = shadow_highlight_correction(corrected, shadow_amount=0.0, highlight_amount=-0.4)
        corrected = gamma_correction(corrected, 1.3)
        correction_log.append("Overexposure correction: highlight recovery + gamma 1.3")
    
    if lighting_info['has_low_contrast']:
        clip_limit = 4.0 if lighting_info['std_brightness'] < 15 else 2.5
        corrected = adaptive_histogram_equalization(corrected, clip_limit=clip_limit)
        correction_log.append(f"Low contrast correction: CLAHE (clip_limit={clip_limit})")
    elif lighting_info['has_uneven_lighting']:
        corrected = adaptive_histogram_equalization(corrected, clip_limit=2.0, tile_grid_size=(6, 6))
        correction_log.append("Uneven lighting correction: Soft CLAHE")
    
    if lighting_info['std_brightness'] < 30:
        corrected = unsharp_masking(corrected, strength=0.3, radius=1.2)
        correction_log.append("Sharpening applied")
        
    return corrected, correction_log

# ==============================================================================
# ëª¨ë¸ ë¡œë“œ ë° ì£¼ìš” í•¨ìˆ˜
# ==============================================================================

def load_models():
    """AI ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¼ëŸ¬ë¥¼ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜"""
    global kmeans_model, scaler, face_detector, face_parser, models_loaded, face_parsing_net
    
    try:
        print("Loading AI models...")
        
        # í¼ìŠ¤ë„ ì»¬ëŸ¬ ì§„ë‹¨ ëª¨ë¸
        kmeans_model = joblib.load(os.path.join(MODEL_DIR, 'kmeans_model.joblib'))
        scaler = joblib.load(os.path.join(MODEL_DIR, 'scaler.joblib'))
        print("âœ“ K-means model and scaler loaded successfully.")

        # Facer ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ì–¼êµ´ ê´€ë ¨ ëª¨ë¸ë“¤
        face_detector = facer.face_detector('retinaface/mobilenet', device=device)
        face_parser = facer.face_parser('farl/celebm/448', device=device)
        print("âœ“ Facer models loaded successfully.")
        
        # ê°€ìƒ ë©”ì´í¬ì—…ìš© ëª¨ë¸ ë¡œë“œ ì¶”ê°€
        face_parsing_net = BiSeNet(n_classes=19)
        # 79999_iter.pth íŒŒì¼ì´ 'res/cp/' í´ë” ì•ˆì— ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
        face_parsing_net.load_state_dict(torch.load('res/cp/79999_iter.pth', map_location='cpu'))
        face_parsing_net.eval()
        print("âœ“ Face Parsing model for makeover loaded successfully.")
        
        print(f"âœ“ Using device: {device}")
        models_loaded = True
    except FileNotFoundError as e:
        print(f"âŒ ERROR: Model file not found. {e}")
    except Exception as e:
        print(f"âŒ An unexpected error occurred during model loading: {e}")
        traceback.print_exc()

def allowed_file(filename):
    """ì—…ë¡œë“œëœ íŒŒì¼ì´ í—ˆìš©ëœ í™•ì¥ìì¸ì§€ í™•ì¸í•˜ëŠ” í•¨ìˆ˜"""
    return '.' in filename and \
           filename.rsplit('.', 1)[1].lower() in app.config['ALLOWED_EXTENSIONS']

def extract_facial_part_colors(image: Image.Image, n_colors_per_part=7, apply_lighting_correction=True, is_camera_input=False):
    """ì–¼êµ´ì—ì„œ í”¼ë¶€ ìƒ‰ìƒ íŠ¹ì§•(Lab ìƒ‰ê³µê°„)ì„ ì¶”ì¶œí•˜ëŠ” í•µì‹¬ í•¨ìˆ˜ (ì¡°ëª… ë³´ì • í¬í•¨)"""
    try:
        image_np = np.array(image)
        
        # ì¹´ë©”ë¼ ì…ë ¥ì˜ ê²½ìš° ë…¸ì´ì¦ˆ ê°ì†Œë¥¼ ìœ„í•´ ì–‘ë°©í–¥ í•„í„° ì ìš©
        if is_camera_input:
            image_np = cv2.bilateralFilter(image_np, d=9, sigmaColor=75, sigmaSpace=75)

        correction_log = []
        if apply_lighting_correction:
            image_np, correction_log = comprehensive_lighting_correction(image_np)
            image = Image.fromarray(image_np)
        
        image_resized = image.resize((448, 448))
        image_tensor = torch.from_numpy(np.array(image_resized)).permute(2, 0, 1).unsqueeze(0).to(device)

        with torch.inference_mode():
            faces = face_detector(image_tensor)
            if len(faces['scores']) == 0 or faces['scores'][0] < 0.5:
                return None, "ì–¼êµ´ì„ ê°ì§€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", []
            faces = face_parser(image_tensor, faces)

        seg_map = faces['seg']['logits'].argmax(dim=1).squeeze(0).cpu().numpy()
        image_lab = cv2.cvtColor(np.array(image_resized), cv2.COLOR_RGB2Lab)
        skin_pixels = image_lab[np.isin(seg_map, [1, 2])]

        if len(skin_pixels) < n_colors_per_part:
            return None, "í”¼ë¶€ ì˜ì—­ì´ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.", correction_log

        kmeans = KMeans(n_clusters=n_colors_per_part, n_init='auto', random_state=42)
        kmeans.fit(skin_pixels.astype(np.float32))
        
        return kmeans.cluster_centers_.astype(np.float32).flatten().reshape(1, -1), None, correction_log

    except Exception as e:
        traceback.print_exc()
        return None, f"ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}", []

def get_cluster_info(cluster_id):
    """í´ëŸ¬ìŠ¤í„° IDì— í•´ë‹¹í•˜ëŠ” í¼ìŠ¤ë„ ì»¬ëŸ¬ ì •ë³´ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜"""
    return CLUSTER_DESCRIPTIONS.get(cluster_id, CLUSTER_DESCRIPTIONS[0])

# ==============================================================================
# ì›¹ ë¼ìš°íŠ¸ ì •ì˜
# ==============================================================================

@app.route('/')
def index():
    """ë©”ì¸ í˜ì´ì§€ë¥¼ ë Œë”ë§í•˜ëŠ” ë¼ìš°íŠ¸"""
    page = request.args.get('page', 'home')
    return render_template('index.html', user=session.get('user'), initial_page=page)

@app.route('/analyze', methods=['POST'])
def analyze():
    """ì´ë¯¸ì§€ ë¶„ì„ì„ ìˆ˜í–‰í•˜ëŠ” ë©”ì¸ API ì—”ë“œí¬ì¸íŠ¸"""
    if 'user' not in session:
        return jsonify({'error': 'ë¡œê·¸ì¸ì´ í•„ìš”í•œ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.'}), 401

    if not models_loaded:
        return jsonify({'error': 'AI ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'}), 503

    try:
        image = None
        is_camera_input = False
        filename = f"upload_{np.datetime64('now').astype(int)}.jpg"
        apply_correction = request.form.get('apply_lighting_correction', 'true').lower() == 'true'
        
        if 'file' in request.files:
            file = request.files['file']
            if file.filename == '' or not allowed_file(file.filename):
                return jsonify({'error': 'ì˜ëª»ëœ íŒŒì¼ì…ë‹ˆë‹¤.'}), 400
            image = Image.open(file.stream).convert('RGB')
        elif request.json and 'image_data' in request.json:
            is_camera_input = True
            image_data = request.json['image_data'].split(',')[1]
            image = Image.open(BytesIO(base64.b64decode(image_data))).convert('RGB')
            apply_correction = request.json.get('apply_lighting_correction', True)
        else:
            return jsonify({'error': 'ì´ë¯¸ì§€ íŒŒì¼ ë˜ëŠ” ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.'}), 400

        lab_features, error_msg, correction_log = extract_facial_part_colors(
            image,
            n_colors_per_part=N_REPRESENTATIVE_COLORS,
            apply_lighting_correction=apply_correction,
            is_camera_input=is_camera_input
        )
        
        if error_msg:
            return jsonify({'error': error_msg}), 400

        scaled_features = scaler.transform(lab_features)
        predicted_cluster = kmeans_model.predict(scaled_features)[0]
        cluster_info = get_cluster_info(predicted_cluster)
        
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], secure_filename(filename))
        image.save(filepath, 'JPEG')

        return jsonify({
            "success": True, "cluster_id": int(predicted_cluster),
            "personal_color_type": cluster_info["name"], "visual_name": cluster_info["visual_name"],
            "type_description": cluster_info["description"], "palette": cluster_info["palette"],
            "uploaded_image_url": f'/uploads/{filename}', "lighting_correction_applied": apply_correction,
            "correction_log": correction_log
        })

    except Exception as e:
        traceback.print_exc()
        return jsonify({'error': f'ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'}), 500

@app.route('/makeover')
def makeover():
    """ê°€ìƒ ìŠ¤íƒ€ì¼ë§ í˜ì´ì§€ë¥¼ ë Œë”ë§í•˜ëŠ” ë¼ìš°íŠ¸"""
    filename = request.args.get('filename')
    cluster_num = request.args.get('cluster_num', type=int)
    palette_num = request.args.get('palette_num', type=int, default=0)

    if not filename or cluster_num is None:
        return "ì˜¤ë¥˜: í•„ìš”í•œ ì •ë³´(íŒŒì¼ ì´ë¦„, í´ëŸ¬ìŠ¤í„° ë²ˆí˜¸)ê°€ ì—†ìŠµë‹ˆë‹¤.", 400

    personal_color_info = get_cluster_info(cluster_num)

    filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
    img_bgr = cv2.imread(filepath)
    if img_bgr is None:
        return "ì˜¤ë¥˜: ì›ë³¸ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", 404
        
    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)

    # ì–¼êµ´ ì˜ì—­ íŒŒì‹±
    img_pil_resized = Image.fromarray(img_rgb).resize((512, 512))
    img_tensor = to_tensor(img_pil_resized).unsqueeze(0)
    with torch.no_grad():
        out = face_parsing_net(img_tensor)[0]
    parsing = out.squeeze(0).cpu().numpy().argmax(0)
    
    # ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ì— ë§ê²Œ íŒŒì‹± ë§ˆìŠ¤í¬ ë¦¬ì‚¬ì´ì¦ˆ
    parsing_resized = np.array(Image.fromarray(parsing.astype(np.uint8)).resize((img_rgb.shape[1], img_rgb.shape[0]), Image.NEAREST))
    
    # ì„ íƒëœ íŒ”ë ˆíŠ¸
    selected_palette = MAKEOVER_PALETTES.get(cluster_num)[palette_num]
    hair_color = hex_to_bgr(selected_palette[0])
    lens_color = hex_to_bgr(selected_palette[1])
    lip_color = hex_to_bgr(selected_palette[2])
    clothes_color = hex_to_bgr(selected_palette[3])

    # ì‚¬ìš©ì ì„±ë³„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    user_sex = None
    if session.get('user') and 'email' in session['user']:
        try:
            db = get_db()
            user_doc = db.collection('users').document(session['user']['email']).get()
            if user_doc.exists:
                user_sex = user_doc.to_dict().get('sex', '').lower()
        except Exception as e:
            print(f"Error fetching user sex from Firestore: {e}")

    # ë©”ì´í¬ì—… ì ìš©
    img_makeup = hair(img_bgr, parsing_resized, 17, hair_color) # í—¤ì–´
    img_makeup = hair(img_makeup, parsing_resized, 16, clothes_color)  # ì˜·
    if user_sex != 'male':
        img_makeup = hair(img_makeup, parsing_resized, 12, lip_color)    # ìœ—ì…ìˆ 
        img_makeup = hair(img_makeup, parsing_resized, 13, lip_color)    # ì•„ë«ì…ìˆ 
    
    # ë Œì¦ˆëŠ” hair í•¨ìˆ˜ë¥¼ ì¬ì‚¬ìš©í•˜ë˜, ë‹¤ë¥¸ íŒŒíŠ¸ ë²ˆí˜¸ì™€ ìƒ‰ìƒì„ ì „ë‹¬
    img_makeup = hair(img_makeup, parsing_resized, 4, lens_color)    # ì™¼ìª½ ëˆˆ
    img_makeup = hair(img_makeup, parsing_resized, 5, lens_color)    # ì˜¤ë¥¸ìª½ ëˆˆ

    # ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥
    result_filename = f"makeover_{palette_num}_{filename}"
    result_path = os.path.join(app.config['UPLOAD_FOLDER'], result_filename)
    cv2.imwrite(result_path, img_makeup)

    return render_template("makeover.html",
                           original_image=filename,
                           result_image=result_filename,
                           palettes=MAKEOVER_PALETTES,
                           selected_cluster=cluster_num,
                           selected_palette=palette_num,
                           personal_color_info=personal_color_info,
                           user=session.get('user'))


@app.route('/developer_makeup')
def developer_makeup_page():
    """ê°œë°œììš© ë©”ì´í¬ì—… í…ŒìŠ¤íŠ¸ í˜ì´ì§€ë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤."""
    if session.get('user') and session['user'].get('name') == 'hanwae':
        return render_template('developer_makeup.html', user=session.get('user'))
    else:
        return "ì ‘ê·¼ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤.", 403

@app.route('/upload_dev_image', methods=['POST'])
def upload_dev_image():
    """ê°œë°œì ë„êµ¬ìš© ì´ë¯¸ì§€ ì—…ë¡œë“œ ì—”ë“œí¬ì¸íŠ¸"""
    if not (session.get('user') and session['user'].get('name') == 'hanwae'):
        return jsonify({'success': False, 'error': 'Not authorized'}), 403
    
    if 'file' not in request.files:
        return jsonify({'success': False, 'error': 'No file part'}), 400
    
    file = request.files['file']
    if file.filename == '':
        return jsonify({'success': False, 'error': 'No selected file'}), 400

    if file and allowed_file(file.filename):
        filename = f"dev_upload_{int(time.time())}_{secure_filename(file.filename)}"
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        file.save(filepath)
        return jsonify({'success': True, 'uploaded_image_url': f'/uploads/{filename}'})
    
    return jsonify({'success': False, 'error': 'File type not allowed'}), 400

@app.route('/apply_makeup_realtime', methods=['POST'])
def apply_makeup_realtime():
    """ì‹¤ì‹œê°„ìœ¼ë¡œ ë©”ì´í¬ì—…ì„ ì ìš©í•˜ê³  ê²°ê³¼ ì´ë¯¸ì§€ URLì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if 'user' not in session:
        return jsonify({'success': False, 'error': 'ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.'}), 403

    data = request.get_json()
    filename = data.get('filename')
    colors = data.get('colors')

    if not filename or not colors:
        return jsonify({'success': False, 'error': 'íŒŒì¼ ì´ë¦„ ë˜ëŠ” ìƒ‰ìƒ ì •ë³´ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.'}), 400

    try:
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        img_bgr = cv2.imread(filepath)
        if img_bgr is None:
            return jsonify({'success': False, 'error': 'ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 404

        img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)

        img_pil_resized = Image.fromarray(img_rgb).resize((512, 512))
        img_tensor = to_tensor(img_pil_resized).unsqueeze(0)
        with torch.no_grad():
            out = face_parsing_net(img_tensor)[0]
        parsing = out.squeeze(0).cpu().numpy().argmax(0)
        parsing_resized = np.array(Image.fromarray(parsing.astype(np.uint8)).resize((img_rgb.shape[1], img_rgb.shape[0]), Image.NEAREST))

        img_makeup = img_bgr.copy()

        if 'hair' in colors and colors['hair']:
            hair_color = hex_to_bgr(colors['hair'])
            img_makeup = hair(img_makeup, parsing_resized, 17, hair_color)
        
        if 'lips' in colors and colors['lips']:
            lip_color = hex_to_bgr(colors['lips'])
            img_makeup = hair(img_makeup, parsing_resized, 12, lip_color)
            img_makeup = hair(img_makeup, parsing_resized, 13, lip_color)

        if 'lens' in colors and colors['lens']:
            lens_color = hex_to_bgr(colors['lens'])
            img_makeup = hair(img_makeup, parsing_resized, 4, lens_color)
            img_makeup = hair(img_makeup, parsing_resized, 5, lens_color)

        if 'clothes' in colors and colors['clothes']:
            clothes_color = hex_to_bgr(colors['clothes'])
            img_makeup = hair(img_makeup, parsing_resized, 16, clothes_color)

        result_filename = f"dev_{int(time.time())}_{filename}"
        result_path = os.path.join(app.config['UPLOAD_FOLDER'], result_filename)
        cv2.imwrite(result_path, img_makeup)

        return jsonify({
            'success': True,
            'result_image_url': f'/uploads/{result_filename}'
        })

    except Exception as e:
        traceback.print_exc()
        return jsonify({'success': False, 'error': f'ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'}), 500

def unique_preserve_order(seq):
    seen = set()
    seen_add = seen.add
    return [x for x in seq if not (x in seen or seen_add(x))]

@app.route('/custom_makeover')
def custom_makeover_page():
    """ì‚¬ìš©ì ë§ì¶¤í˜• ë©”ì´í¬ì—… í˜ì´ì§€ë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤."""
    if 'user' not in session:
        return "ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.", 401

    filename = request.args.get('filename')
    cluster_num = request.args.get('cluster_num', type=int)

    if not filename or cluster_num is None:
        return "í•„ìˆ˜ ì •ë³´(íŒŒì¼ ì´ë¦„, í´ëŸ¬ìŠ¤í„° ë²ˆí˜¸)ê°€ ì—†ìŠµë‹ˆë‹¤.", 400

    try:
        # í´ëŸ¬ìŠ¤í„° ì •ë³´ì™€ í¼ìŠ¤ë„ ì»¬ëŸ¬ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
        personal_color_info = get_cluster_info(cluster_num)
        personal_color_name = personal_color_info.get("name")

        # JSON ë°ì´í„° ë¡œë“œ
        json_path = os.path.join(app.static_folder, 'data', 'colors.json')
        with open(json_path, 'r', encoding='utf-8') as f:
            all_colors_data = json.load(f)

        # í•´ë‹¹ í¼ìŠ¤ë„ ì»¬ëŸ¬ì— ë§ëŠ” ìƒ‰ìƒ íŒ”ë ˆíŠ¸ ì¶”ì¶œ
        raw_palettes = all_colors_data.get(personal_color_name, {})
        
        # ìƒ‰ìƒ ì²˜ë¦¬: ì¤‘ë³µ ì œê±° ë° ìŠ¬ë¼ì´ì‹±
        processed_palettes = {
            'hair': unique_preserve_order(raw_palettes.get('hair', [])),
            'lipstick': unique_preserve_order(raw_palettes.get('lipstick', [])),
            'lens': unique_preserve_order(raw_palettes.get('lens', [])),
            'clothing': unique_preserve_order(raw_palettes.get('clothing', []))
        }

        return render_template(
            'custom_makeover.html',
            user=session.get('user'),
            original_image=filename,
            cluster_num=cluster_num,
            personal_color_info=personal_color_info,
            color_palettes=processed_palettes
        )
    except Exception as e:
        traceback.print_exc()
        return f"í˜ì´ì§€ ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", 500

@app.route('/download_report', methods=['POST'])
def download_report():
    """ê²°ê³¼ ë¦¬í¬íŠ¸ PDFë¥¼ ìƒì„±í•˜ê³  ë‹¤ìš´ë¡œë“œí•˜ëŠ” ë¼ìš°íŠ¸"""
    data = request.get_json()
    original_image = data.get('original_image')
    result_image = data.get('result_image')
    cluster_num = data.get('cluster_num')

    if not all([original_image, result_image, cluster_num is not None]):
        return jsonify({'status': 'error', 'message': 'í•„ìˆ˜ ì •ë³´ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.'}), 400

    try:
        cluster_info = get_cluster_info(cluster_num)
        original_image_path = os.path.join(app.config['UPLOAD_FOLDER'], original_image)
        result_image_path = os.path.join(app.config['UPLOAD_FOLDER'], result_image)

        # PDF ìƒì„±
        pdf_path = generate_report_pdf(
            original_image_path,
            result_image_path,
            cluster=cluster_num,
            CLUSTER_DESCRIPTIONS=CLUSTER_DESCRIPTIONS,
            output_folder=app.config['UPLOAD_FOLDER']
        )

        return send_file(pdf_path, as_attachment=True)

    except FileNotFoundError as e:
        traceback.print_exc()
        return jsonify({'status': 'error', 'message': f'íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}'}), 404
    except Exception as e:
        traceback.print_exc()
        return jsonify({'status': 'error', 'message': f'ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}'}), 500


@app.route('/uploads/<filename>')
def uploaded_file(filename):
    """ì—…ë¡œë“œëœ ì´ë¯¸ì§€ íŒŒì¼ì„ ì œê³µí•˜ëŠ” ë¼ìš°íŠ¸"""
    return send_from_directory(app.config['UPLOAD_FOLDER'], filename)

@app.route('/guide')
def guide():
    """ì»¬ëŸ¬ ê°€ì´ë“œ í˜ì´ì§€ë¥¼ ë Œë”ë§í•˜ëŠ” ë¼ìš°íŠ¸"""
    return render_template('guide.html', user=session.get('user'))

@app.route('/about')
def about():
    """íŒ€ ì†Œê°œ í˜ì´ì§€ë¥¼ ë Œë”ë§í•˜ëŠ” ë¼ìš°íŠ¸"""
    return render_template('about.html', user=session.get('user'))

# ==============================================================================
# ì‚¬ìš©ì ì¸ì¦ ê´€ë ¨ ë¼ìš°íŠ¸
# ==============================================================================

@app.route('/signup', methods=['POST'])
def signup():
    data = request.get_json(silent=True)
    if not data or not all(k in data for k in ['name', 'password', 'email', 'sex']):
        return jsonify({'status': 'error', 'message': 'Missing required fields'}), 400

    db = get_db()
    users = db.collection('users')

    # Check if name (ID) already exists
    name_query = users.where(field_path='name', op_string='==', value=data['name']).limit(1).stream()
    if next(name_query, None) is not None:
        return jsonify({'status': 'error', 'message': 'ID already exists'}), 400

    # Check if email already exists
    doc_ref = users.document(data['email'])
    if doc_ref.get().exists:
        return jsonify({'status': 'error', 'message': 'Email already exists'}), 400
    
    # ë¹„ë°€ë²ˆí˜¸ë¥¼ í•´ì‹±í•˜ì—¬ ì €ì¥
    hashed_password = generate_password_hash(data['password'])
    
    user_data = {
        'name': data['name'],
        'email': data['email'],
        'sex': data['sex'],
        'password': hashed_password
    }
    
    doc_ref.set(user_data)
    
    return jsonify({'status': 'success'}), 200

@app.route('/login', methods=['POST'])
def login():
    data = request.get_json(silent=True)
    if not data or not all(k in data for k in ['name', 'password']):
        return jsonify({'status': 'error', 'message': 'Missing name or password'}), 400

    db = get_db()
    users = db.collection('users')
    
    login_identifier = data['name']
    password = data['password']
    
    user_doc = None
    # Check if the identifier is an email
    if '@' in login_identifier:
        doc_ref = users.document(login_identifier)
        user_doc = doc_ref.get()
    else:
        # Assume it's a name/ID
        query = users.where(field_path='name', op_string='==', value=login_identifier).limit(1).stream()
        user_doc = next(query, None)

    user_data = user_doc.to_dict() if user_doc and user_doc.exists else None

    if user_data is None:
        return jsonify({'status': 'error', 'message': 'Invalid name or password'}), 401

    stored_password = user_data.get('password', '')
    
    # Use check_password_hash directly. It safely handles non-hashed strings by returning False.
    # Then, check for plaintext password for legacy support.
    if check_password_hash(stored_password, password) or stored_password == password:
        # If it was a plaintext password, hash it and update the DB.
        if not stored_password.startswith('pbkdf2:sha256') and stored_password == password:
            try:
                new_hashed_password = generate_password_hash(password)
                users.document(user_doc.id).update({'password': new_hashed_password})
                print(f"Password for user {user_data['name']} has been securely hashed.")
            except Exception as e:
                print(f"Error updating password for user {user_data['name']}: {e}")
        
        # If we are here, the password is correct.
        user_session_data = {
            'name': user_data.get('name'),
            'email': user_data.get('email'),
            'sex': user_data.get('sex'),
            'image': None if not user_data.get('image') else f"/user_image/{user_data.get('name')}"
        }
        session['user'] = user_session_data
        
        return jsonify({'status': 'success', 'user': user_session_data}), 200

    # If both checks fail, the password is wrong.
    return jsonify({'status': 'error', 'message': 'Invalid name or password'}), 401

@app.route('/logout', methods=['POST'])
def logout():
    session.clear()
    return jsonify({'status': 'success'}), 200

@app.route('/me', methods=['GET'])
def get_profile():
    if not session.get('user'):
        return jsonify({'status': 'error', 'message': 'Not logged in'}), 401
    return jsonify({'status': 'success', 'user': session['user']}), 200


# ==============================================================================
# ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„
# ==============================================================================
if __name__ == '__main__':
    load_models()
    
    print("=" * 70)
    print(f"ğŸš€ Enhanced Personal Color & Makeover Server Starting...")
    print(f"ğŸ“± Model Status: {{'âœ… Loaded' if models_loaded else 'âŒ Failed'}}")
    print(f"ğŸ–¥ï¸  Device: {device}")
    print(f"ğŸŒ Server: http://127.0.0.1:5001")
    print("=" * 70)
    
    app.run(debug=True, host='0.0.0.0', port=5001)
